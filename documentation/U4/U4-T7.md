# Unidad 4: Infraestructura y Despliegue
## Tema 7: Docker y Contenerización

> [Back to Menu](../../README.md)

### ST1. Conceptos básicos de Docker y contenerización.

En el desarrollo moderno de software, Docker se ha convertido en una herramienta esencial para crear aplicaciones portátiles y eficientes. Docker permite empaquetar una aplicación junto con todas sus dependencias en una imagen de contenedor, garantizando que se ejecutará de la misma manera en cualquier entorno, sin importar el sistema operativo o las configuraciones locales. Esto resuelve problemas comunes como “en mi máquina funciona” y facilita la integración y despliegue de aplicaciones en diferentes infraestructuras, desde entornos de desarrollo hasta producción en la nube.

La contenerización con Docker no solo mejora la portabilidad, sino que también optimiza el uso de recursos al permitir que múltiples aplicaciones o servicios corran de manera aislada en el mismo sistema sin interferencias. Con un enfoque práctico, en este tema exploraremos cómo crear, gestionar y ejecutar contenedores con Docker en .NET, aprendiendo a estructurar nuestras aplicaciones de forma eficiente y escalable.

#### ¿Qué es la contenerización?

La contenerización es una técnica de virtualización ligera que permite empaquetar una aplicación junto con todas sus dependencias en un contenedor. Un contenedor es una unidad de software que incluye el código de la aplicación, sus bibliotecas, configuraciones y cualquier otra dependencia necesaria para que funcione correctamente en cualquier entorno.

Imagina que tienes una aplicación que depende de una versión específica de una base de datos, un framework y ciertas configuraciones del sistema. Si intentas ejecutarla en diferentes computadoras o servidores, podrías encontrarte con problemas como incompatibilidades de versiones o configuraciones que no coinciden. La contenerización resuelve esto al proporcionar un entorno aislado y autocontenido donde la aplicación siempre se ejecutará de la misma manera, sin importar dónde se despliegue.

Para entenderlo mejor, pensemos en una aplicación como una receta de cocina. Si solo das la receta sin ingredientes ni herramientas, la persona que la reciba puede tener problemas para reproducir el mismo resultado, ya que su cocina puede ser diferente a la tuya. En cambio, si le das una caja con todos los ingredientes, las herramientas exactas y las instrucciones, podrá hacer la receta en cualquier lugar sin preocuparse por diferencias en el entorno. Esa caja es el equivalente a un contenedor en el mundo del desarrollo de software.

##### Tipos de Contenerización

Existen diferentes enfoques para la contenerización, dependiendo de cómo se gestionan los contenedores y qué nivel de aislamiento proporcionan.

1. Contenedores de Aplicación

    Estos contenedores están diseñados para ejecutar una sola aplicación o servicio dentro de un entorno aislado. Son la forma más común de contenerización y son ideales para aplicaciones microservicio.

    **Ejemplo:**
    Si tienes una aplicación con una base de datos, una API y un frontend, puedes crear tres contenedores separados:

    * Un contenedor para la base de datos.

    * Un contenedor para la API.

    * Un contenedor para el frontend.

    Cada uno funcionará independientemente pero podrá comunicarse con los otros según sea necesario.

2. Contenedores de Sistema

    A diferencia de los contenedores de aplicación, los contenedores de sistema pueden ejecutar múltiples procesos y servicios, funcionando de manera similar a una máquina virtual, pero sin el peso de un sistema operativo completo.

    **Ejemplo:**
    Un contenedor de sistema puede tener un servidor web, una base de datos y herramientas de administración en un solo contenedor, simulando un entorno completo sin necesidad de una VM.

3. Contenedores Privilegiados
    
    Estos contenedores tienen permisos elevados y pueden acceder directamente a los recursos del sistema anfitrión. Son usados para tareas de administración y pruebas de seguridad.

    **Ejemplo:**
    Un contenedor que ejecuta herramientas de monitoreo para analizar el rendimiento del servidor donde está corriendo.

##### Ventajas de la Contenerización

La contenerización ha revolucionado la forma en que desarrollamos, implementamos y escalamos aplicaciones. Algunas de sus principales ventajas son:

1. Portabilidad
    
    * Un contenedor empaqueta una aplicación con todas sus dependencias, lo que significa que puede ejecutarse en cualquier entorno sin preocuparse por problemas de compatibilidad. Puedes ejecutar el mismo contenedor en tu laptop, en un servidor o en la nube sin cambios.

2. Rápido Tiempo de Inicio
    
    * Los contenedores son livianos y no requieren un sistema operativo completo, lo que permite que se inicien en cuestión de segundos, a diferencia de las máquinas virtuales que tardan minutos.

3. Eficiencia en Recursos
    
    * Como los contenedores comparten el mismo sistema operativo, utilizan menos CPU, memoria y almacenamiento en comparación con las VMs, permitiendo que un servidor ejecute muchos más contenedores de los que podría ejecutar en máquinas virtuales.

4. Escalabilidad
    
    * Las aplicaciones en contenedores pueden escalar fácilmente al agregar o eliminar instancias según la demanda. Esto es especialmente útil en arquitecturas basadas en microservicios, donde cada parte de una aplicación se ejecuta en su propio contenedor.

5. Aislamiento
    
    * Cada contenedor es un entorno independiente, lo que significa que una aplicación en un contenedor no afectará a otra. Esto es útil para evitar conflictos de dependencias y mejorar la seguridad.

6. Facilidad de Desarrollo y Despliegue
    
    * Gracias a la contenerización, los desarrolladores pueden crear entornos de desarrollo que sean idénticos a los entornos de producción, reduciendo los problemas de compatibilidad y asegurando que el código funcione de la misma manera en todos los entornos.


#### ¿Qué es la Virtualización?

La virtualización es el proceso de crear una versión virtual de un recurso de hardware o software. En términos sencillos, permite que un solo servidor físico actúe como si fueran varios, ejecutando múltiples sistemas operativos y aplicaciones de manera simultánea e independiente.

Esto se logra mediante una capa de software llamada hipervisor, que permite crear y gestionar máquinas virtuales (VMs, por sus siglas en inglés). Cada máquina virtual tiene su propio sistema operativo, aplicaciones y configuraciones, pero comparte los recursos del hardware físico con otras VMs.

Para entenderlo mejor, piensa en un edificio de oficinas. Antes, cada empresa necesitaba su propio edificio (un servidor físico dedicado), lo que generaba costos elevados y mucho espacio desperdiciado. Con la virtualización, ese mismo edificio se divide en oficinas separadas (máquinas virtuales), donde cada empresa (aplicación o sistema operativo) tiene su propio espacio aislado sin interferir con las demás.

##### ¿Cómo Funciona la Virtualización?

La virtualización se basa en tres elementos clave:

1. Hardware físico: El servidor real con su CPU, memoria, almacenamiento y otros recursos.

2. Hipervisor: Un software que actúa como intermediario entre el hardware y las máquinas virtuales, permitiendo que cada VM reciba una porción de los recursos físicos.

3. Máquinas Virtuales (VMs): Son entornos aislados que funcionan como si fueran computadoras independientes, cada una con su propio sistema operativo y aplicaciones.

Cuando se ejecuta una aplicación dentro de una VM, el hipervisor traduce las solicitudes de la VM para que se comuniquen con el hardware real. De esta manera, múltiples VMs pueden compartir el mismo hardware sin interferencias.

##### Tipos de Virtualización
Existen diferentes tipos de virtualización, cada una diseñada para resolver necesidades específicas:

1. Virtualización de Servidores:

    * Permite dividir un servidor físico en múltiples servidores virtuales.
    
    * Ejemplo: Un solo servidor físico puede ejecutar varias instancias de Windows y Linux al mismo tiempo.
    
2. Virtualización de Escritorios:

    * Se utilizan escritorios virtuales accesibles desde cualquier dispositivo.
    
    * Ejemplo: Un usuario puede conectarse a su escritorio de Windows desde una tablet, laptop o teléfono sin importar el hardware.

3. Virtualización de Redes:

    * Se crean redes virtuales independientes dentro de una red física.
    
    * Ejemplo: Un centro de datos puede asignar redes virtuales separadas para distintos clientes sin necesidad de hardware adicional.

4. Virtualización de Almacenamiento:

    * Agrupa diferentes dispositivos de almacenamiento en un solo sistema virtual.

    * Ejemplo: Un sistema de almacenamiento en la nube donde los archivos se almacenan en múltiples servidores físicos sin que el usuario lo note.

##### Hipervisores: El Corazón de la Virtualización

Los hipervisores son software especializado que permiten crear y gestionar máquinas virtuales. Se dividen en dos tipos:

1. Hipervisores Tipo 1 (Nativos o Bare-Metal):

    * Se ejecutan directamente sobre el hardware sin necesidad de un sistema operativo base.

    * Son más rápidos y eficientes porque tienen acceso directo a los recursos físicos.

    * Ejemplo: VMware ESXi, Microsoft Hyper-V, KVM.

2. Hipervisores Tipo 2 (Alojados):

    * Se instalan dentro de un sistema operativo y dependen de él para gestionar las máquinas virtuales.
    
    * Son más fáciles de usar, pero tienen menor rendimiento en comparación con los Tipo 1.
    
    * Ejemplo: VirtualBox, VMware Workstation, Parallels.

Si necesitas ejecutar una VM en tu computadora personal para pruebas, probablemente uses un hipervisor Tipo 2, como VirtualBox. En cambio, si eres un administrador de sistemas en una empresa, seguramente usarás un hipervisor Tipo 1, como VMware ESXi, para manejar múltiples servidores virtuales en un centro de datos.

##### Ventajas de la Virtualización
* Ahorro de Costos: Se reduce la necesidad de comprar múltiples servidores físicos.

* Mayor Eficiencia: Permite un mejor aprovechamiento del hardware disponible.

* Escalabilidad: Es fácil agregar más VMs sin necesidad de hardware adicional.

* Aislamiento y Seguridad: Cada VM funciona de manera independiente, evitando que fallos en una afecten a las demás.

* Facilidad de Administración: Se pueden hacer copias de seguridad, migraciones y despliegues de forma rápida y sencilla.


#### Diferencias entre Virtualización y Conteinerización.

Imagina que tienes una computadora muy potente, pero solo puedes ejecutar una aplicación a la vez. Sería un desperdicio de recursos, ¿verdad? Ahora piensa en un centro de datos con cientos de servidores físicos, cada uno destinado a una sola aplicación. Además del enorme consumo de energía, espacio y mantenimiento, gran parte del poder de procesamiento de esos servidores quedaría inutilizado.

Aquí es donde entra la virtualización, una tecnología que permite dividir los recursos de una sola máquina física en múltiples entornos virtuales independientes, maximizando su uso y optimizando la administración de sistemas. Es como si una misma computadora pudiera transformarse en varias computadoras más pequeñas dentro de ella misma.

Aunque la contenerización y la virtualización permiten ejecutar múltiples aplicaciones en un mismo servidor, hay una diferencia clave:

**Virtualización:** Cada aplicación se ejecuta dentro de una máquina virtual que incluye su propio sistema operativo. Esto hace que las VMs sean más pesadas y consuman más recursos.

**Contenerización:** Todos los contenedores comparten el mismo sistema operativo del servidor, lo que los hace mucho más ligeros y rápidos.

|Característica|Máquinas Virtuales (VMs)|Contenedores|
|---|---|---|
|Tiempo de inicio|Minutos|Segundos|
|Tamaño|GB (Sistema operativo incluido)|MB (Sin sistema operativo)|
|Eficiencia|Menos eficiente (consume más recursos)|Más eficiente (comparte recursos)|
|Portabilidad|Menos portátil (depende del hipervisor)|Altamente portátil (se ejecuta en cualquier máquina con un contenedor compatible)|
|Aislamiento|Alto (cada VM es completamente independiente)|Medio (comparten el kernel del sistema operativo)|

Esto significa que los contenedores son ideales para aplicaciones rápidas, escalables y portátiles, mientras que las máquinas virtuales son más adecuadas para casos donde se requiere un aislamiento total entre sistemas.

**Conclusión**

La contenerización ha cambiado la manera en que las empresas desarrollan y despliegan software, permitiendo mayor eficiencia, escalabilidad y portabilidad en la ejecución de aplicaciones. Con su capacidad de empaquetar aplicaciones junto con todas sus dependencias en un solo contenedor, garantiza que los desarrolladores puedan construir aplicaciones que se ejecuten de forma consistente en cualquier lugar.

Si bien la contenerización puede parecer un concepto avanzado, herramientas como Docker han facilitado su adopción, permitiendo que cualquier desarrollador pueda empezar a trabajar con contenedores en cuestión de minutos. En los próximos temas, exploraremos cómo Docker hace posible la contenerización y cómo se pueden gestionar múltiples contenedores de manera eficiente.

> [Back to Menu](../../README.md)

### ST2. Creación de Dockerfiles para aplicaciones .NET.

#### Hablemos de Docker

**La revolución de la contenerización**

Docker es una de las tecnologías más influyentes en el mundo del desarrollo y despliegue de software. Desde su lanzamiento en 2013, ha cambiado la forma en que las aplicaciones son empaquetadas, distribuidas y ejecutadas. Gracias a Docker, los desarrolladores pueden crear aplicaciones que funcionen de la misma manera en cualquier entorno, eliminando el famoso problema de "en mi máquina sí funciona".

En esta guía, exploraremos qué es Docker, cómo funciona, cómo almacena los contenedores, su ecosistema (incluido Docker Hub) y algunos cambios recientes que han impactado la comunidad.

##### ¿Qué es Docker?

Docker es una plataforma de contenerización que permite a los desarrolladores empaquetar aplicaciones junto con todas sus dependencias en contenedores livianos y portátiles. Con Docker, no es necesario preocuparse por si el sistema operativo, la configuración o las versiones del software son diferentes entre entornos de desarrollo y producción.

###### ¿Cómo funciona Docker?

Docker utiliza una arquitectura cliente-servidor que permite crear, administrar y ejecutar contenedores. Su funcionamiento se basa en tres componentes principales:

1. Docker Daemon (dockerd): Es el servicio en segundo plano que se encarga de gestionar los contenedores. Recibe órdenes del cliente Docker y ejecuta las operaciones necesarias.

2. Docker CLI (Interfaz de Línea de Comandos): Es la herramienta que permite interactuar con Docker a través de comandos como docker run, docker build o docker ps.

3. Docker Hub y Registros Privados: Son repositorios donde se almacenan y comparten imágenes de contenedores.

Cuando ejecutas docker run, lo que sucede internamente es:

1. Docker busca la imagen solicitada en el equipo local.

2. Si la imagen no está disponible localmente, la descarga desde Docker Hub u otro registro.

3. Docker crea un contenedor basado en esa imagen.

4. El contenedor se ejecuta en un entorno aislado pero puede comunicarse con otros contenedores si es necesario.

##### Almacenamiento y gestión de contenedores en Docker

Cuando creas una aplicación en Docker, en realidad estás utilizando imágenes y contenedores.

* Imagen: Es una plantilla inmutable que contiene el sistema operativo base, el código de la aplicación y las dependencias necesarias.

* Contenedor: Es una instancia en ejecución de una imagen. Puedes tener múltiples contenedores basados en la misma imagen.

Docker almacena estos contenedores utilizando layers (capas), lo que significa que solo se guardan los cambios entre versiones de una imagen en lugar de duplicar todo el contenido. Esto reduce el consumo de almacenamiento y permite compartir partes comunes entre distintos contenedores.

Los datos dentro de un contenedor no son persistentes por defecto. Si necesitas almacenamiento permanente, puedes usar:

* Volumes: Espacios de almacenamiento gestionados por Docker.

* Bind Mounts: Carpetas del sistema anfitrión accesibles desde el contenedor.

##### ¿Qué es Docker Hub y cómo funciona?

Docker Hub es un registro de imágenes de Docker en la nube, similar a un "GitHub para contenedores". Es el repositorio oficial donde los desarrolladores pueden:

* Descargar imágenes listas para usar, como nginx, mysql o redis.

* Subir sus propias imágenes y compartirlas con otros.

* Automatizar la construcción y despliegue de imágenes con integración continua.

Existen registros privados como Amazon Elastic Container Registry (ECR), Google Container Registry (GCR) o Azure Container Registry (ACR), donde las empresas pueden almacenar imágenes sin hacerlas públicas.

##### Algunos cambios recientes en Docker 

A lo largo de los años, Docker ha evolucionado y ha tomado decisiones estratégicas que han impactado a la comunidad. Algunos de los cambios más importantes desde 2023 incluyen:

1. Privatización de Docker Hub para ciertos usos.
    
    Docker anunció restricciones en su política de almacenamiento gratuito en Docker Hub. Anteriormente, cualquier usuario podía almacenar imágenes ilimitadamente, pero ahora:

    - Las cuentas gratuitas tienen un límite de inactividad (si no se usa una imagen por varios meses, se elimina).
    - Para proyectos de código abierto, Docker ofrece programas especiales para evitar la eliminación de imágenes.
    - Las cuentas empresariales deben suscribirse a planes pagos para acceso avanzado y mayor almacenamiento.

2. Eliminación de Docker Desktop para empresas sin licencia.

    Docker Desktop, la aplicación gráfica para gestionar contenedores en Windows y macOS, ahora requiere licencia paga para empresas con más de 250 empleados. Sin embargo, sigue siendo gratuito para desarrolladores individuales y pequeñas empresas.

3. Cambios en la integración con Kubernetes.

    Docker ha reducido su soporte nativo para Kubernetes dentro de Docker Desktop, promoviendo el uso de herramientas especializadas como kind (Kubernetes in Docker) o k3s.

    Estos cambios han impulsado a la comunidad a buscar alternativas como Podman, pero Docker sigue siendo la herramienta más utilizada en producción.

Docker ha revolucionado el desarrollo de software al hacer que las aplicaciones sean portátiles, escalables y fáciles de desplegar. Su modelo basado en imágenes y contenedores permite a los equipos trabajar de manera más eficiente, sin preocuparse por diferencias entre entornos de desarrollo y producción.

A pesar de los cambios recientes en sus políticas, Docker sigue siendo la opción principal para la contenerización de aplicaciones. Con un conocimiento sólido de imágenes, contenedores, Docker Hub y su almacenamiento interno, cualquier desarrollador puede aprovechar el poder de Docker para construir aplicaciones modernas y escalables.


##### ¿Qué es un Dockerfile?

Cuando trabajamos con Docker, una de las primeras cosas que encontramos es el Dockerfile, un archivo esencial que le indica a Docker cómo construir una imagen de nuestra aplicación. Imagina que quieres compartir un pastel con alguien, pero en lugar de enviárselo ya hecho, le das la receta para que pueda prepararlo exactamente como tú lo hiciste. Un Dockerfile es, en esencia, esa receta para los contenedores.

A través de un Dockerfile, definimos todo lo que un contenedor necesita para ejecutarse correctamente: el sistema operativo base, las dependencias, el código fuente de la aplicación, las configuraciones y el comando que debe ejecutarse cuando el contenedor inicie. Con esta información, Docker puede tomar nuestra receta y generar una imagen lista para usarse en cualquier máquina sin necesidad de configuraciones adicionales.

Imagina que quieres compartir tu aplicación con amigos sin que tengan que lidiar con instalaciones complicadas. Un Dockerfile es como una receta que le dice a Docker cómo construir una imagen de tu aplicación, incluyendo todos los ingredientes necesarios: código, dependencias y configuraciones. Con esta imagen, cualquiera puede ejecutar tu aplicación en un contenedor sin preocuparse por configuraciones adicionales.

###### ¿Cómo Funciona un Dockerfile?

El Dockerfile es un archivo de texto sin extensión que contiene una serie de instrucciones que Docker interpreta secuencialmente para construir una imagen. Algunas de las instrucciones más comunes incluyen:

* `FROM`: Define la imagen base sobre la que construiremos nuestro contenedor. Puede ser una distribución de Linux ligera (como alpine) o una imagen especializada para ciertos lenguajes, como .NET, Node.js o Python.

* `WORKDIR`: Establece el directorio en el que trabajará el contenedor dentro de la imagen.

* `COPY` o `ADD`: Permite copiar archivos desde la máquina anfitriona al contenedor. Esto se usa para incluir el código fuente de la aplicación y otros archivos necesarios.

* `RUN`: Ejecuta comandos dentro del contenedor durante la construcción de la imagen. Suele usarse para instalar dependencias o realizar configuraciones.

* `CMD` y `ENTRYPOINT`: Definen qué comando se ejecutará cuando el contenedor inicie.

Supongamos que tenemos una aplicación de consola en .NET y queremos crear un Dockerfile para ejecutarla en un contenedor. Nuestro archivo se vería así:

```dockerfile
# 1. Usamos una imagen base de .NET 8
FROM mcr.microsoft.com/dotnet/runtime:8.0  

# 2. Definimos el directorio de trabajo dentro del contenedor
WORKDIR /app  

# 3. Copiamos el archivo de la aplicación compilada al contenedor
COPY MiAplicacion.dll .  

# 4. Especificamos el comando que ejecutará la aplicación
ENTRYPOINT ["dotnet", "MiAplicacion.dll"]
```

Este Dockerfile le indica a Docker lo siguiente:

1. Usar una imagen de .NET 8 como base (porque queremos ejecutar una aplicación .NET).

2. Establecer el directorio de trabajo dentro del contenedor en /app.

3. Copiar nuestro archivo compilado (MiAplicacion.dll) al contenedor.

4. Ejecutar la aplicación con dotnet MiAplicacion.dll cuando el contenedor inicie.

##### Ventajas de Usar Dockerfiles

Usar un Dockerfile tiene múltiples ventajas:

* Reproducibilidad: Cualquier persona puede construir la misma imagen y obtener el mismo resultado, sin importar su sistema operativo.

* Automatización: Se pueden integrar en pipelines de CI/CD para que las aplicaciones se construyan y desplieguen automáticamente.

* Portabilidad: Una vez creada la imagen, podemos ejecutarla en cualquier servidor o nube sin preocuparnos por configuraciones de entorno.

* Facilidad de mantenimiento: Si necesitamos actualizar algo en la aplicación o sus dependencias, solo editamos el Dockerfile y reconstruimos la imagen.

##### ¡Manos a la obra!

Antes de escribir nuestro Dockerfile, necesitamos una aplicación .NET. Si aún no tienes una, no te preocupes, [¡la crearemos juntos!](https://learn.microsoft.com/es-es/dotnet/core/docker/build-container?tabs=windows)

Recordemos cómo crear una nueva aplicación de consola: Abre tu terminal o línea de comandos y ejecuta:

```bash
dotnet new console -o MiAppDockerizada
```

Este comando crea una carpeta llamada MiAppDockerizada con una aplicación de consola básica.

Navegamos al directorio de la aplicación:

```bash
cd MiAppDockerizada
```

Probamos la aplicación:

```bash
dotnet run
```
Deberías ver un mensaje diciendo "Hello, World!".

**Escribiendo el Dockerfile**

Ahora que tenemos nuestra aplicación, vamos a crear el Dockerfile para contenerizarla.

1. Crea un archivo llamado Dockerfile (sin extensión) en el directorio raíz de tu aplicación.

2. Abre el archivo y añade las siguientes líneas:

```dockerfile
# Etapa 1: Construcción
FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build-env
WORKDIR /app

# Copia los archivos de proyecto y restaura las dependencias
COPY *.csproj ./
RUN dotnet restore

# Copia el resto del código y compila la aplicación
COPY . ./
RUN dotnet publish -c Release -o out

# Etapa 2: Imagen de runtime
FROM mcr.microsoft.com/dotnet/runtime:8.0
WORKDIR /app
COPY --from=build-env /app/out .

# Comando para ejecutar la aplicación
ENTRYPOINT ["dotnet", "MiAppDockerizada.dll"]
```

###### Vamos a desglosar este Dockerfile:

*Etapa 1: Construcción:*

`FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build-env`: Usa la imagen del SDK de .NET 8.0 para compilar la aplicación.

`WORKDIR /app`: Establece el directorio de trabajo en `/app`.

`COPY *.csproj ./`: Copia el archivo de proyecto `.csproj` al contenedor.

`RUN dotnet restore`: Restaura las dependencias especificadas en el `.csproj`.

`COPY . ./`: Copia el resto del código al contenedor.

`RUN dotnet publish -c Release -o out`: Compila la aplicación en modo Release y la publica en la carpeta `out`.

*Etapa 2: Imagen de runtime:*

`FROM mcr.microsoft.com/dotnet/runtime:8.0`: Usa la imagen de runtime de .NET 8.0, más ligera que el SDK.

`WORKDIR /app`: Establece el directorio de trabajo en `/app`.

`COPY --from=build-env /app/out .`: Copia los archivos compilados desde la etapa de construcción.

`ENTRYPOINT ["dotnet", "MiAppDockerizada.dll"]`: Define el comando para ejecutar la aplicación cuando el contenedor se inicie.

Este enfoque se conoce como compilación en múltiples etapas, y ayuda a mantener las imágenes de Docker más pequeñas y eficientes. Puedes profundizar en este tema en la [documentación oficial de Docker](https://docs.docker.com/get-started/docker-concepts/building-images/writing-a-dockerfile/).

> [Back to Menu](../../README.md)

### ST3. Contenerización de la API.

Hoy en día, desarrollar aplicaciones web escalables, seguras y portables es una necesidad fundamental. Con la contenerización, podemos garantizar que nuestras aplicaciones funcionen de manera uniforme en cualquier entorno sin preocuparnos por diferencias en sistemas operativos o configuraciones. Para lograr esto con una API en .NET, utilizamos Dockerfiles, archivos que definen paso a paso cómo construir una imagen de contenedor lista para ejecutarse en cualquier servidor o nube.

Este concepto es clave en el desarrollo moderno, y en esta introducción, exploraremos por qué los Dockerfiles son esenciales, cómo funcionan y cómo estructurar uno específicamente para una API en .NET.

#### ¿Por Qué Usar Docker para una API en .NET?
Una API en .NET, al igual que cualquier aplicación web, necesita varios elementos para ejecutarse correctamente: un entorno de ejecución, dependencias, archivos de configuración y seguridad en el despliegue. Tradicionalmente, configurar estos entornos en cada máquina o servidor podía ser un proceso tedioso y propenso a errores.

Docker soluciona este problema al encapsular la API junto con todo lo que necesita en un contenedor autocontenido. Esto nos da varias ventajas:

* Portabilidad: La API se ejecutará de la misma manera en desarrollo, prueba y producción sin cambios de configuración.

* Escalabilidad: Podemos ejecutar múltiples instancias de la API fácilmente para soportar más tráfico.

* Facilidad de despliegue: Implementar la API en la nube o en servidores locales se vuelve un proceso sencillo y automatizable.

* Aislamiento: Cada contenedor es independiente, evitando conflictos entre diferentes versiones de dependencias.

Para lograr esto, debemos escribir un Dockerfile que encapsule las necesidadesd e nuestra API en .NET.

#### Estructura de un Dockerfile para una API en .NET

Cuando trabajamos con .NET y Docker, es importante entender que una aplicación web en .NET Core o .NET 8+ requiere dos fases dentro del Dockerfile:

* Construcción: En esta fase, compilamos la API y generamos los archivos listos para ejecutarse.

* Ejecución: En esta fase, utilizamos una imagen optimizada para correr la API con el menor consumo de recursos posible.

La mejor práctica es usar un Dockerfile multi-stage, donde utilizamos una imagen para compilar y otra imagen más liviana para ejecutar la API en producción.

El ejemplo de Dockerfile para una API en .NET 8 es igual a los ejemplos que ya hemos visto anteriormente, se genera de la misma forma, debemos recordar que esto es debido a que .Net al final de toda su compilación genera paquetes o librerías (.dll) que son las encargadas de ejecutar nuestro código. Debido a esto, a menos que nuestra librería use servicios externos, específicos, todos nuestros Dockerfiles se verán de manera similar.

```dockerfile
# Fase 1: Construcción de la API
FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build-env
WORKDIR /app

# Copiar archivos del proyecto y restaurar dependencias
COPY *.csproj ./
RUN dotnet restore

# Copiar el resto del código y compilar
COPY . ./
RUN dotnet publish -c Release -o out

# Fase 2: Ejecución de la API en una imagen más liviana
FROM mcr.microsoft.com/dotnet/aspnet:8.0
WORKDIR /app

# Copiar los archivos compilados desde la fase anterior
COPY --from=build-env /app/out .

# Exponer el puerto en el que correrá la API
EXPOSE 8080

# Comando de inicio de la API
ENTRYPOINT ["dotnet", "MiAPI.dll"]

```

##### Explicación Paso a Paso

Veamos en detalle qué hace cada parte de este Dockerfile:

1. Fase de construcción (`FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build-env`)

* Utilizamos la imagen oficial de .NET SDK para compilar la aplicación.

* Establecemos un directorio de trabajo dentro del contenedor con `WORKDIR /app`.

* Copiamos los archivos `.csproj` y ejecutamos `dotnet restore` para instalar dependencias.

* Copiamos el resto del código y ejecutamos `dotnet publish` en la terminal para generar los archivos compilados.

2. Fase de ejecución (`FROM mcr.microsoft.com/dotnet/aspnet:8.0`)

* Usamos una imagen de ASP.NET 8.0, que es más liviana que el SDK y solo contiene lo necesario para ejecutar la API.

* Copiamos los archivos compilados desde la fase anterior.

* Exponemos el puerto `8080` para que la API pueda recibir peticiones.

* Definimos el comando de inicio con `ENTRYPOINT ["dotnet", "MiAPI.dll"]`, que arranca la API cuando el contenedor se ejecuta.

##### ¿Cómo Construir y Ejecutar una API con este Dockerfile?

Una vez que tenemos nuestro Dockerfile listo, podemos generar una imagen y correr nuestra API con los siguientes comandos en una terminal dentro del proyecto:

1. Construir la imagen.

```bash
docker build -t mi-api .
```
Este comando le dice a Docker que cree una imagen con el nombre `mi-api` a partir del Dockerfile en la carpeta actual `(.)`.

2. Ejecutar la API dentro de un contenedor.

```bash
docker run -p 8080:8080 mi-api
```

Esto inicia la API en un contenedor, redirigiendo el puerto `8080` del contenedor al puerto `8080` de la máquina host, para que podamos acceder a la API desde un navegador o Postman.

Crear un Dockerfile para una API en .NET nos permite contenerizar nuestra aplicación de manera eficiente, asegurando que pueda ejecutarse de forma consistente en cualquier entorno. Al usar una estrategia multi-stage, optimizamos el tamaño y rendimiento del contenedor, separando la construcción de la aplicación de su ejecución.

Si deseas profundizar en la documentación oficial sobre estos conceptos, te recomiendamos los siguientes recursos:

* [Documentación de Docker para .NET](https://learn.microsoft.com/es-es/dotnet/core/docker/introduction)

Ahora que tienes la base, puedes comenzar a experimentar creando y optimizando tus propios Dockerfiles para APIs en .NET. ¡El siguiente paso será integrarlos con herramientas como Docker Compose para gestionar múltiples contenedores! 


> [!NOTE]
> Ahora bien, es cierto que .NET genera archivos compilados en formato `.dll`, los cuales pueden ejecutarse en un entorno compatible con .NET (como una imagen base de `mcr.microsoft.com/dotnet/aspnet:8.0`). Esto significa que muchos Dockerfiles para aplicaciones .NET pueden parecerse, ya que la estructura general del proceso de compilación y ejecución es la misma.
>
> Sin embargo, hay algunas excepciones y detalles a tener en cuenta:
>
> 1. No todas las aplicaciones .NET son iguales
>
>    * Una API en .NET usa ASP.NET Core y necesita la imagen de `mcr.microsoft.com/dotnet/aspnet` para ejecutarse.
>
>    * Una aplicación de consola puede necesitar solo `mcr.microsoft.com/dotnet/runtime` en lugar de `aspnet`.
>
>    * Una aplicación con dependencias externas, como bases de datos, servicios de mensajería o autenticación, podría requerir configuraciones adicionales en el Dockerfile.
>
> 2. Diferencias en la configuración según el entorno
>
>    * Algunas aplicaciones pueden requerir variables de entorno o archivos de configuración específicos.
>
>    * Puede ser necesario agregar pasos adicionales como configuración de volúmenes, logs o integración con otros servicios.
>
> 3. Personalización en el Dockerfile
>
>    * Si la API necesita dependencias del sistema (como `libgdiplus` para procesamiento de imágenes o `openssl` para encriptación), el Dockerfile deberá incluir comandos adicionales (`RUN apt-get install`).
>
>    * En algunos casos, podemos necesitar un entrypoint script para configurar la aplicación antes de ejecutarla.
>
> Por lo tanto, aunque la estructura general de un Dockerfile para una API en .NET es similar a la de otras aplicaciones .NET, cada caso puede requerir personalizaciones según las necesidades del proyecto.
>


> [Back to Menu](../../README.md)

### Conclusión

A lo largo de este tema, hemos explorado los fundamentos de la contenerización y el papel crucial que juega Docker en la modernización del desarrollo y despliegue de aplicaciones. La contenerización ha revolucionado la forma en que ejecutamos software al proporcionar entornos aislados, ligeros y portables, eliminando problemas comunes como la incompatibilidad entre sistemas o la necesidad de configuraciones específicas en cada máquina de desarrollo.

Docker, como tecnología líder en contenerización, simplifica la creación, empaquetado y distribución de aplicaciones en entornos controlados y reproducibles. A través de Dockerfiles, hemos visto cómo definir la estructura de un contenedor y cómo Docker Hub facilita el acceso y la gestión de imágenes preconfiguradas. Además, comprendimos que, aunque todos los Dockerfiles de aplicaciones .NET pueden parecer similares, cada proyecto tiene sus particularidades dependiendo de sus dependencias externas, configuraciones y servicios asociados.

El uso de contenedores no solo optimiza el desarrollo local, sino que también mejora el despliegue en producción, facilitando la escalabilidad y la integración con arquitecturas modernas como microservicios. Con esta base, estamos preparados para profundizar en aspectos más avanzados como la orquestación de contenedores con Docker Compose, lo que nos permitirá manejar múltiples servicios en conjunto de manera eficiente.

Este es solo el inicio del camino en la contenerización. Docker es una herramienta poderosa, pero su verdadero potencial se desbloquea cuando se integra con prácticas de automatización, CI/CD y despliegue en la nube. A medida que avanzamos, veremos cómo estas tecnologías pueden transformar la forma en que construimos y entregamos software en entornos modernos.

> [Back to Menu](../../README.md)